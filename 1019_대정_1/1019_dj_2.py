import os
import pandas as pd
from sklearn.metrics import accuracy_score
import numpy as np
import warnings
from google.colab import drive
import torch
from torch.utils.data import Dataset # Dataset ì„í¬íŠ¸ ìœ ì§€
# EarlyStoppingCallback ë° EvaluationStrategy ê´€ë ¨ ì„í¬íŠ¸ ì œê±°
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, BertTokenizer 

warnings.filterwarnings("ignore")

# ==============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° í™˜ê²½ ì„¤ì •
# ==============================================================================
drive.mount('/content/drive') 

DATA_PATH = "/content/drive/MyDrive/nlp_contest"
df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))
df_valid = pd.read_csv(os.path.join(DATA_PATH, 'valid.csv')) # ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ ë¡œë“œ
df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))
print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

# D. ëª¨ë¸ ì •ì˜ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
MODEL_NAME = "monologg/kobert"  
MAX_LEN = 146            # ğŸš¨ EDA ê²°ê³¼ì— ë”°ë¼ 146ìœ¼ë¡œ ì„¤ì •
BATCH_SIZE = 32          
NUM_EPOCHS = 3        # ğŸš¨ 5 Epochìœ¼ë¡œ ë³€ê²½
LEARNING_RATE = 3e-5     

# ==============================================================================
# 2. ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ (Dataset ë° Tokenizer)
# ==============================================================================
tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)
class SentimentDataset(Dataset):
    def __init__(self, texts, labels=None):
        self.texts = texts
        self.labels = labels
    def __len__(self):
        return len(self.texts)
    def __getitem__(self, idx):
        encoding = tokenizer(
            str(self.texts[idx]), 
            truncation=True, 
            padding='max_length', 
            max_length=MAX_LEN, 
            return_tensors='pt'
        )
        item = {key: val.squeeze() for key, val in encoding.items()}
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

train_dataset = SentimentDataset(df_train['text'].tolist(), df_train['label'].tolist())
valid_dataset = SentimentDataset(df_valid['text'].tolist(), df_valid['label'].tolist())
test_texts = df_test['text'].tolist()
test_dataset = SentimentDataset(test_texts)
print("âœ… Dataset ê°ì²´ ìƒì„± ì™„ë£Œ")

# ==============================================================================
# 3. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (5 Epoch ë‹¨ìˆœ ë°˜ë³µ)
# ==============================================================================
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("âœ… KoBERT ëª¨ë¸ ë¡œë“œ ë° GPU/CPU í• ë‹¹ ì™„ë£Œ")

def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)
    return {"accuracy": accuracy_score(p.label_ids, preds)}

# TrainingArguments ì„¤ì • (ì˜¤ë¥˜ ìœ ë°œ íŒŒë¼ë¯¸í„° ì œê±°)
training_args = TrainingArguments(
    output_dir='./results',                    
    num_train_epochs=NUM_EPOCHS,               # ğŸš¨ 5 Epoch ì‹¤í–‰
    per_device_train_batch_size=BATCH_SIZE,    
    per_device_eval_batch_size=BATCH_SIZE,     
    warmup_steps=500,                          
    weight_decay=0.01,                         
    logging_dir='./logs',                      
    logging_steps=500,
    learning_rate=LEARNING_RATE,
    # ğŸš¨ ì˜¤ë¥˜ ìœ ë°œ íŒŒë¼ë¯¸í„° ì „ë¶€ ì œê±°
    report_to="none"                           
)

# D. Trainer ê°ì²´ ìƒì„± (Callback ë° eval_dataset ì œê±°)
trainer = Trainer(
    model=model,                               
    args=training_args,                        
    train_dataset=train_dataset,               
    # eval_dataset=valid_dataset,             # ê²€ì¦ì€ ìƒëµí•˜ê³  í•™ìŠµì—ë§Œ ì§‘ì¤‘
    compute_metrics=compute_metrics,           
    # callbacksëŠ” ì œê±°
)

print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
trainer.train()
print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# ==============================================================================
# 4. ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„± (ìµœì¢… 5 Epoch ëª¨ë¸ë¡œ ì˜ˆì¸¡)
# ==============================================================================
print("â¡ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...")
predictions = trainer.predict(test_dataset) 

predicted_labels = np.argmax(predictions.predictions, axis=1)

submission = pd.DataFrame({
    'Id': df_test['id'],
    'label': predicted_labels
})

SUBMISSION_PATH = os.path.join(DATA_PATH, 'submission.csv')
submission.to_csv(SUBMISSION_PATH, index=False)

print("\nğŸ‰ ìµœì¢… ì˜ˆì¸¡ ì™„ë£Œ ë° submission.csv íŒŒì¼ ìƒì„±!")
print("íŒŒì¼ ê²½ë¡œ: {}".format(SUBMISSION_PATH))
print("ì œì¶œ í˜•ì‹ í™•ì¸ (ìƒìœ„ 5ê°œ):")
print(submission.head())